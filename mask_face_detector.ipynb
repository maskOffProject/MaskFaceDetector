{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mask Face Detector**"
      ],
      "metadata": {
        "id": "CM0MEB56LW7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preperations**"
      ],
      "metadata": {
        "id": "pr3g4sJCP1wI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jrfDD_3VuNH"
      },
      "source": [
        "### **General Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrbElJ6NBXPJ"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdkqCeo9WApD"
      },
      "source": [
        "### **Consts declaration and preparations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTgdtR2xCMYP"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE=0.0003\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 8\n",
        "WIDTH=224\n",
        "\n",
        "mixed_images_path = \"./Face Mask Dataset/\"\n",
        "mixed_images_train_path = mixed_images_path + \"Train\"\n",
        "mixed_images_validation_path = mixed_images_path + \"Validation\"\n",
        "mixed_images_test_path = mixed_images_path + \"Test\"\n",
        "\n",
        "paired_images_path = \"./pair_face_divided/\"\n",
        "paired_white_path = paired_images_path + \"white_masks/\"\n",
        "paired_blue_path = paired_images_path + \"blue_masks/\"\n",
        "paired_black_path = paired_images_path + \"black_masks/\"\n",
        "\n",
        "combined_path = './combined_dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybxUgRogWFyD"
      },
      "source": [
        "### **Data and Pre Proccessing**\n",
        "Loading all data(all colors generated masks), pre proccessing it and adds augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbq_JxIwCdbp",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# remvcing corrupted files\n",
        "all_paths = [mixed_images_train_path, mixed_images_validation_path, mixed_images_test_path,\n",
        "             paired_white_path, paired_blue_path, paired_black_path]\n",
        "for path in all_paths:\n",
        "    corrupted_folder_path = os.path.join(path, '.ipynb_checkpoints')\n",
        "    if os.path.exists(corrupted_folder_path):\n",
        "        shutil.rmtree(corrupted_folder_path)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWvUjwBCw_y"
      },
      "outputs": [],
      "source": [
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "combined_training_set = aug.flow_from_directory(mixed_images_train_path,\n",
        "                                                 target_size = (WIDTH, WIDTH),\n",
        "                                                 batch_size = BATCH_SIZE,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "combined_validation_set = validation_datagen.flow_from_directory(mixed_images_validation_path,\n",
        "                                                 target_size = (WIDTH, WIDTH),\n",
        "                                                 batch_size = BATCH_SIZE,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "combined_test_set = aug.flow_from_directory(mixed_images_test_path,\n",
        "                                                 target_size = (WIDTH, WIDTH),\n",
        "                                                 batch_size = BATCH_SIZE,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36YR7aI2WRFw"
      },
      "source": [
        "## **Building the Model**\n",
        "The functions that build the model's architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sSPeGMKLRui"
      },
      "outputs": [],
      "source": [
        "# load the MobileNetV2 network\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(WIDTH, WIDTH, 3)))\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "headModel = Flatten(name=\"flatten_end\")(headModel)\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWyeSzJ8WYGg"
      },
      "source": [
        "## **Training the Model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training the Model**\n",
        "Putting everything together - loading the dataset created and commiting the training"
      ],
      "metadata": {
        "id": "U0jQlZQbQS7T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVDqqYtfUI-I"
      },
      "outputs": [],
      "source": [
        "# compile our model\n",
        "opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "callback = callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "steps_per_epoch = len(training_set) \n",
        "validation_steps = len(validation_set)\n",
        "H =model.fit(x = combined_training_set, validation_data = combined_validation_set,epochs=EPOCHS,steps_per_epoch=steps_per_epoch,validation_steps =validation_steps,shuffle=True, callbacks=[callback])\n",
        "model.save('detector_model.h5', save_format=\"h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOe_wJWVSiJj"
      },
      "source": [
        "### **Training Results**\n",
        "Summarize of the model's training's results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PbGkpqFUtBN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Models Architecture**\n",
        "Displaying the model's architecture"
      ],
      "metadata": {
        "id": "suAlVPo7SEEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek-ekudXLRuj"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model, spacing=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results**"
      ],
      "metadata": {
        "id": "Lbijr33CS1q-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ROUp_LIWhT0"
      },
      "source": [
        "### **Test Results**\n",
        "Summarize of the model's test's results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBpIYk0JUg02"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('detector_model.h5')\n",
        "predIdxs = model.predict(combined_test_set, batch_size=BATCH_SIZE)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(combined_test_set.labels, predIdxs,\n",
        "\ttarget_names=combined_test_set.class_indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Making a Single Prediction**\n",
        "Detecting all the masks on a single image"
      ],
      "metadata": {
        "id": "RmY1OjezSKsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNUy4fSVVGoI"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp5Eb9naWxYm"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
        "# load the input image from disk, clone it, and grab the image spatial dimensions\n",
        "detectorModel = load_model('detector_model.h5')\n",
        "image = cv2.imread(\"detector-example.png\")\n",
        "\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "# Detect the faces\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "print(len(faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkZGLjk2W5Wd"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# loop over the detections\n",
        "for (x, y, w, h) in faces:\n",
        "\n",
        "  # compute the (x, y)-coordinates of the bounding box for\n",
        "  # the object\n",
        "  (startX, startY, endX, endY) = (x, y, x+w, y+h)\n",
        "\n",
        "  # extract the face ROI, convert it from BGR to RGB channel\n",
        "  # ordering, resize it to 224x224, and preprocess it\n",
        "  face = image[startY:endY, startX:endX]\n",
        "  face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "  face = cv2.resize(face, (224, 224))\n",
        "  face = img_to_array(face)\n",
        "  face = preprocess_input(face)\n",
        "  face = np.expand_dims(face, axis=0)\n",
        "  # pass the face through the model to determine if the face\n",
        "  # has a mask or not\n",
        "  (mask, withoutMask) = detectorModel.predict(face)[0]\n",
        "\n",
        "\n",
        "  # determine the class label and color we'll use to draw\n",
        "  # the bounding box and text\n",
        "  label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "  color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "  # include the probability in the label\n",
        "  label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "  # display the label and bounding box rectangle on the output\n",
        "  # frame\n",
        "  cv2.putText(image, label, (startX, startY - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "  cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "# show the output image\n",
        "# cv2.imshow(\"hey\", image)\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "pyplot.imshow(image)\n",
        "pyplot.axis('off')\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mask face detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}